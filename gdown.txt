features:
- should be able to download single files, directories from any public repos to the current directory
- should be able to download files of certain type (.cpp files or .txt files)
- should be able to download all the files / directories as a zip file in the current directory
- should be able to download all the files / directories as a zip file in the current directory and extract the files in the current directory

additional features:
- should be able to quickly download multiple files and directories under a repo or directory
- instead of directly download contents, we can zip everything into a single file

process:
- Use the github's rest api to recursively get the contents of a directory and download the contents
- Then zip the whole contents and then save it in the current directory

other details:
- use async functions to download files (espcially the large ones)
- use sync functions to create directories (since they need to be created first before proceeding to download all other stuff)
- think what to do about symlinks (which make our directory tree a graph)
- try to use core node modules as much as possible
- cannot directly use fs.writeFile() to create(download) files, we have to use streams (check about streams in node)

issues faced:
- API rate limit exceeped for my ip address... How to solve this issue? 
(Currently github only supports upto 60 requests per hour from unauthorized requests)

solutions available for the above issues:
- use an auth token to get upto 5000 requests per hour. But, even this won't be enough for large file/directory sizes
(Other tools built around this: 
1. downgit - 60 requests/hr
2. gitzip - 5000 requests/hr)